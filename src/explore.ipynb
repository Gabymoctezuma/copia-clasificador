{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Sistema de clasificación de imágenes\n",
    "El conjunto de datos se compone de fotos de perros y gatos proporcionadas como un subconjunto de fotos de uno mucho más grande de 3 millones de fotos anotadas manualmente. Estos datos se obtuvieron a través de una colaboración entre Petfinder.com y Microsoft.\n",
    "\n",
    "El conjunto de datos se usó originalmente como un CAPTCHA, es decir, una tarea que se cree que un humano encuentra trivial, pero que una máquina no puede resolver, que se usa en sitios web para distinguir entre usuarios humanos y bots. La tarea se denominó \"Asirra\". Cuando se presentó \"Asirra\", se mencionó \"que los estudios de usuarios indican que los humanos pueden resolverlo el 99,6% de las veces en menos de 30 segundos\". A menos que se produzca un gran avance en la visión artificial, esperamos que los ordenadores no tengan más de 1/54.000 posibilidades de resolverlo.\n",
    "\n",
    "En el momento en que se publicó la competencia, el resultado de última generación se logró con un SVM y se describió en un artículo de 2007 con el título \"Ataques de Machine Learning contra el CAPTCHA de Asirra\" (PDF) que logró una precisión de clasificación del 80%. Fue este documento el que demostró que la tarea ya no era una tarea adecuada para un CAPTCHA poco después de que se propusiera la tarea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"salader/dogs-vs-cats\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"/home/vscode/.cache/kagglehub/datasets/salader/dogs-vs-cats/versions/1\"\n",
    "\n",
    "# Listar archivos en la carpeta\n",
    "files = os.listdir(dataset_path)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Ruta a la carpeta \"train\" que contiene \"cats\" y \"dogs\"\n",
    "image_folder = os.path.join(dataset_path, \"train\")\n",
    "\n",
    "# Recorrer subcarpetas y recolectar imágenes\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for label in os.listdir(image_folder):\n",
    "    class_folder = os.path.join(image_folder, label)\n",
    "    if os.path.isdir(class_folder):\n",
    "        for file in os.listdir(class_folder):\n",
    "            if file.lower().endswith(\".jpg\"):\n",
    "                image_paths.append(os.path.join(class_folder, file))\n",
    "                labels.append(label)  # 'cats' o 'dogs'\n",
    "\n",
    "# Crear el DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"filepath\": image_paths,\n",
    "    \"filename\": [os.path.basename(path) for path in image_paths],\n",
    "    \"label\": labels\n",
    "})\n",
    "\n",
    "# Verificar\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame como CSV\n",
    "import os\n",
    "ruta=\"/workspaces/Clasficador-Imagenes/data\"\n",
    "train_csv_path = os.path.join(ruta, \"train.csv\")\n",
    "df.to_csv(train_csv_path, index=False)\n",
    "\n",
    "print(f\"Archivo CSV guardado en: {train_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Obtener rutas de perros y gatos\n",
    "dog_images = df[df[\"label\"] == \"dogs\"][\"filepath\"].tolist()[:9]\n",
    "cat_images = df[df[\"label\"] == \"cats\"][\"filepath\"].tolist()[:9]\n",
    "\n",
    "# Función para mostrar 9 imágenes\n",
    "def show_images(image_paths, title):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, path in enumerate(image_paths):\n",
    "        img = Image.open(path)\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar\n",
    "show_images(dog_images, \"Primeras 9 imágenes de perros\")\n",
    "show_images(cat_images, \"Primeras 9 imágenes de gatos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Parámetros\n",
    "image_size = (200, 200)\n",
    "batch_size = 32\n",
    "\n",
    "# Crear generador de datos con validación incluida\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2  # Usamos el 20% para validación\n",
    ")\n",
    "\n",
    "# Generador para entrenamiento\n",
    "train_generator= datagen.flow_from_directory(\n",
    "    directory=image_folder,         # carpeta que contiene \"cats\" y \"dogs\"\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Generador para validación\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    directory=image_folder,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the Data Through the Neural Network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape = (200,200,3), filters = 64, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 64,kernel_size = (3,3),padding = \"same\", activation = \"relu\"))\n",
    "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 4096,activation = \"relu\"))\n",
    "model.add(Dense(units = 4096,activation = \"relu\"))\n",
    "model.add(Dense(units = 1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_generator, epochs=1, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"../models/vgg16_1.h5\", monitor = \"val_accuracy\", verbose = 1, save_best_only = True, save_weights_only = False, mode = \"auto\")\n",
    "early = EarlyStopping(monitor = \"val_accuracy\", patience = 3, verbose = 1, mode = \"auto\")\n",
    "hist = model.fit(train_generator, steps_per_epoch = 100, validation_data =val_generator, validation_steps = 10, epochs = 3, callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Guardar el modelo\n",
    "from pickle import dump\n",
    "\n",
    "dump(model, open(\"../models/model_clasificador_42.sav\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Accuracy of the Data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the Results\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history[\"val_accuracy\"])\n",
    "plt.plot(hist.history[\"loss\"])\n",
    "plt.plot(hist.history[\"val_loss\"])\n",
    "\n",
    "# Configure the Plot Layout\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\", \"Loss\", \"Validation Loss\"])\n",
    "\n",
    "# Plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el modelo guardado\n",
    "model = load_model(\"../models/vgg16_1.h5\")\n",
    "\n",
    "# Ruta de una imagen para probar (puedes cambiar la ruta por otra imagen del set)\n",
    "img_path = df.iloc[200]['filepath']  # o puedes poner la ruta manualmente como: \"../data/raw/train/cat.123.jpg\"\n",
    "\n",
    "# Preprocesar la imagen\n",
    "img = image.load_img(img_path, target_size=(200, 200))  # Asegúrate de usar el mismo tamaño que usaste para entrenar\n",
    "img_array = image.img_to_array(img) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Hacer predicción\n",
    "prediction = model.predict(img_array)\n",
    "predicted_class = np.argmax(prediction)\n",
    "class_labels = list(train_generator.class_indices.keys())\n",
    "\n",
    "print(\"Clase predicha:\", class_labels[predicted_class])\n",
    "print(\"Probabilidades:\", prediction)\n",
    "\n",
    "# Mostrar la imagen\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Predicción: {class_labels[predicted_class]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
